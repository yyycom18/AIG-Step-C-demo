# Project03 - Implementation Guide for Fixes

**For**: Development Team  
**Date**: January 11, 2026  
**Task**: Apply critical fixes from Code Review

---

## üöÄ QUICK START

1. **Read the fixes**: `FIXES_PATCH.md`
2. **Apply files in this order**:
   - `fetch_data.py` (FIX #6)
   - `analysis.py` (FIX #1, #2, #3)
   - `strategy_backtest.py` (FIX #4, #5)
   - `run_server.py` (Import fix)
3. **Test everything** using the testing checklist
4. **Mark as complete** once all tests pass

---

## üìÇ FILE CHANGE SUMMARY

### File: `fetch_data.py`
**Fixes**: Error handling improvement  
**Changes**: Lines 33-89  
**Risk Level**: Low - Non-breaking, better error messages  
**Estimated Time**: 20 minutes

**What changes:**
- More specific exception handling (ValueError, KeyError, ConnectionError)
- Data validation (empty data checks)
- Better error messages with context
- Missing data quality warnings

**Testing:**
```bash
python fetch_data.py
# Should see better error messages if FRED API has issues
```

---

### File: `analysis.py`
**Fixes**: Lead-lag logic, exception handling, code readability  
**Changes**: Lines 27-339  
**Risk Level**: HIGH - Changes core analysis logic  
**Estimated Time**: 90 minutes

**Critical change - FIX #1 (Lines 71-122):**
- **What**: Lead-lag array slicing was backwards
- **Impact**: All lead-lag analysis results were INVERTED
- **Example**: 
  - Before: lag=-1 meant "Y leads X" ‚ùå WRONG
  - After: lag=-1 means "X leads Y" ‚úÖ CORRECT
- **How to test**:
  ```python
  # Create synthetic data where X leads Y by 1
  x = [0, 1, 2, 3, 4, 5]
  y = [0, 0, 1, 2, 3, 4]  # Y is X delayed by 1
  
  # After fix should show lag=-1 as highest correlation
  ```

**Secondary changes - FIX #2 (Lines 48-68, 71-122, 124-148):**
- Replace bare `except:` with specific exceptions
- Add data validation and warnings
- Better error messages

**Code quality - FIX #3 (Lines 248-334):**
- Extract complex summary logic into helper function
- Make extraction more readable and robust
- Prevent IndexError crashes

**Additional improvements:**
- Add docstrings for lead-lag interpretation
- Add data validation in correlation_analysis()
- Add check for constant values (zero variance)

---

### File: `strategy_backtest.py`
**Fixes**: Sharpe ratio calculation, regime assignment efficiency  
**Changes**: Lines 31-168  
**Risk Level**: MEDIUM - Affects performance metrics and calculations  
**Estimated Time**: 60 minutes

**FIX #4 (Lines 100-167) - Sharpe Ratio:**
- **What**: Add risk-free rate to calculation
- **Current formula**: `Sharpe = Return / Volatility` ‚ùå WRONG
- **Correct formula**: `Sharpe = (Return - Risk_Free_Rate) / Volatility` ‚úÖ CORRECT
- **Added metrics**: Sortino ratio (downside volatility only)
- **Impact**: Metrics will show different numbers - this is CORRECT, not a bug
- **Configuration**: RISK_FREE_RATE constant at top (currently 4.0%)

**FIX #5 (Lines 31-97) - Regime Assignment:**
- **What**: Replace `.apply(axis=1)` with `np.select()` (vectorized)
- **Performance**: ~10x faster for large datasets
- **Configuration**: Move position sizes to POSITION_SIZES dictionary
- **Impact**: Results should be identical, just faster

---

### File: `run_server.py`
**Fixes**: Import organization  
**Changes**: Line 7-8  
**Risk Level**: None - Just an import  
**Estimated Time**: 2 minutes

**What changes:**
- Add `import sys` at top with other imports
- Move from line 58 to line 7

---

## üîç BEFORE/AFTER COMPARISONS

### Lead-Lag Fix Example

**BEFORE (Wrong):**
```
Lag | Correlation | Interpretation
-12 | 0.15        | ?
... | ...         | ?
-1  | 0.28        | X leads Y ‚ùå ACTUALLY INVERTED
0   | 0.22        | Current
1   | 0.25        | Y leads X ‚ùå ACTUALLY INVERTED
```

**AFTER (Correct):**
```
Lag | Correlation | Interpretation
-12 | 0.15        | X leads Y by 12 months
... | ...         | ...
-1  | 0.28        | X leads Y by 1 month ‚úÖ CORRECT
0   | 0.22        | No lead/lag (current)
1   | 0.25        | Y leads X by 1 month ‚úÖ CORRECT
```

### Sharpe Ratio Fix Example

**BEFORE (Wrong):**
```json
{
  "spy": {
    "annualized_return": 12.5,
    "volatility": 15.0,
    "sharpe_ratio": 0.83  // (12.5 / 15.0)
  }
}
```

**AFTER (Correct - assuming 4% risk-free rate):**
```json
{
  "spy": {
    "annualized_return": 12.5,
    "excess_return": 8.5,  // (12.5 - 4.0)
    "volatility": 15.0,
    "sharpe_ratio": 0.57,  // (8.5 / 15.0)
    "sortino_ratio": 0.68  // NEW
  }
}
```

### Performance: Regime Assignment

**BEFORE (Slow):**
```
df['Regime'] = df.apply(lambda row: define_regime(...), axis=1)
# Time for 400 rows: ~2.5 seconds
```

**AFTER (Fast):**
```
df['Regime'] = np.select(conditions, choices, default='Unknown')
# Time for 400 rows: ~0.25 seconds (10x faster!)
```

---

## ‚úÖ STEP-BY-STEP IMPLEMENTATION

### Step 1: Backup Current Files
```bash
# Create backup before making changes
copy fetch_data.py fetch_data.py.backup
copy analysis.py analysis.py.backup
copy strategy_backtest.py strategy_backtest.py.backup
copy run_server.py run_server.py.backup
```

### Step 2: Apply FIX #6 (fetch_data.py)
**Time: 20 minutes**

1. Open `fetch_data.py`
2. Replace lines 33-89 with new error handling code from `FIXES_PATCH.md`
3. Test:
   ```bash
   python fetch_data.py
   ```
4. Expected: Should run successfully or show better error messages

### Step 3: Apply FIX #1 (analysis.py)
**Time: 40 minutes** ‚ö†Ô∏è CRITICAL

1. Open `analysis.py`
2. Replace entire `lead_lag_analysis()` function (lines 71-122)
3. Add docstring explaining interpretation:
   ```
   lag < 0: X leads Y (X is earlier, predicts Y)
   lag = 0: Contemporaneous
   lag > 0: Y leads X (Y is earlier, predicts X)
   ```
4. Test immediately:
   ```bash
   python analysis.py 2>&1 | grep -A 5 "Lead-Lag"
   ```
5. Verify output makes sense (e.g., "Best lag: -1 months")

### Step 4: Apply FIX #2 (analysis.py)
**Time: 30 minutes**

1. Replace bare `except:` clauses at lines 66, 114, 141, 145
2. Use specific exception types: `(ValueError, TypeError)`
3. Add print statements for debugging
4. Test:
   ```bash
   python analysis.py
   ```

### Step 5: Apply FIX #3 (analysis.py)
**Time: 20 minutes**

1. Add helper function `safe_extract_correlation()` before `run_full_analysis()`
2. Refactor lines 304-324 to use helper
3. Test JSON output:
   ```bash
   python -m json.tool outputs/analysis_summary.json
   ```

### Step 6: Apply FIX #4 (strategy_backtest.py)
**Time: 40 minutes** ‚ö†Ô∏è AFFECTS METRICS

1. Add `RISK_FREE_RATE = 4.0` constant at top
2. Update `calculate_performance_metrics()` signature
3. Replace Sharpe ratio calculations
4. Add Sortino ratio calculations
5. Update metrics dictionary
6. Test:
   ```bash
   python strategy_backtest.py
   ```
7. **IMPORTANT**: Sharpe ratios will be LOWER than before - this is CORRECT!
   - Before: Ignored risk-free rate
   - After: Subtracts risk-free rate (industry standard)

### Step 7: Apply FIX #5 (strategy_backtest.py)
**Time: 30 minutes**

1. Add `POSITION_SIZES` dictionary at module level
2. Replace `backtest_strategy()` function (lines 47-97)
3. Replace `.apply()` with `np.select()`
4. Replace `get_position_size()` function with `.map()`
5. Add data validation checks
6. Test:
   ```bash
   python strategy_backtest.py
   ```
7. Results should be IDENTICAL to before (just faster)

### Step 8: Update run_server.py
**Time: 2 minutes**

1. Add `import sys` to line 7 (with other imports)
2. Remove `import sys` from line 58

### Step 9: Final Testing
**Time: 30 minutes**

Run all checks:
```bash
# 1. Fetch data
python fetch_data.py
if errorlevel 1 goto error

# 2. Run analysis
python analysis.py
if errorlevel 1 goto error

# 3. Run backtest
python strategy_backtest.py
if errorlevel 1 goto error

# 4. Verify JSON files
python -m json.tool data/hyig_data.json > nul
python -m json.tool outputs/analysis_summary.json > nul
python -m json.tool outputs/strategy_backtest.json > nul

# 5. Test server
python run_server.py &
timeout 5 > nul
taskkill /F /IM python.exe

echo All tests passed!
:error
echo Test failed!
```

---

## ‚ö†Ô∏è EXPECTED METRIC CHANGES

### After FIX #4 (Sharpe Ratio):

**Before (Wrong):**
```
SPY Sharpe Ratio:        1.24
Strategy Sharpe Ratio:   1.15
```

**After (Correct, assuming 4% risk-free rate):**
```
SPY Sharpe Ratio:        0.61
Strategy Sharpe Ratio:   0.52
```

**This is NOT a bug!** The numbers decreased because:
- Old formula: `Return / Volatility` (wrong)
- New formula: `(Return - Risk_Free_Rate) / Volatility` (correct)
- The difference is the risk-free rate (4%) being subtracted

### New Field: Sortino Ratio

**Before:** Not calculated  
**After:** Added for both SPY and Strategy

---

## üß™ VALIDATION TESTS

### Test 1: Lead-Lag Logic
```python
# Create synthetic data where X clearly leads Y
import numpy as np
from scipy import stats

x = np.array([0, 1, 2, 3, 4, 5, 4, 3, 2, 1])
y = np.array([0, 0, 1, 2, 3, 4, 3, 2, 1, 0])  # Y = X delayed by 1

# Should show strongest correlation at lag=-1
# BEFORE: Would show at lag=1 ‚ùå
# AFTER: Shows at lag=-1 ‚úÖ
```

### Test 2: Exception Handling
```bash
# Run with invalid FRED key
set FRED_API_KEY=invalid_key_xyz
python fetch_data.py

# Should show clear error message about invalid key
# BEFORE: Generic error
# AFTER: Specific error with guidance
```

### Test 3: Performance
```python
import time
import pandas as pd

# Benchmark regime assignment
df = pd.read_csv("data/hyig_spy_monthly.csv", index_col=0, parse_dates=True)

# BEFORE (.apply)
start = time.time()
for _ in range(10):
    result = df.apply(lambda row: get_position_size(row['Regime']), axis=1)
before_time = time.time() - start

# AFTER (np.select)
start = time.time()
for _ in range(10):
    result = np.select(conditions, choices, default='Unknown')
after_time = time.time() - start

print(f"Before: {before_time:.2f}s")
print(f"After: {after_time:.2f}s")
print(f"Speedup: {before_time/after_time:.1f}x")
# Expected: ~10x faster
```

---

## üìä SIGN-OFF CHECKLIST

- [ ] All 6 fixes applied to their respective files
- [ ] Code compiles without syntax errors
- [ ] `python fetch_data.py` completes successfully
- [ ] `python analysis.py` completes successfully
- [ ] `python strategy_backtest.py` completes successfully
- [ ] All JSON files are valid (can be parsed)
- [ ] Lead-lag results show correct interpretation (lag=-1 for X leads)
- [ ] Sharpe ratios are lower than before (expected - now using risk-free rate)
- [ ] Sortino ratio is now included in output
- [ ] Server starts without port conflicts: `python run_server.py`
- [ ] Website displays correctly at http://localhost:8001
- [ ] No new warnings or errors in console output

---

## üö® ROLLBACK PROCEDURE

If anything breaks:
```bash
# Restore from backup
copy fetch_data.py.backup fetch_data.py
copy analysis.py.backup analysis.py
copy strategy_backtest.py.backup strategy_backtest.py
copy run_server.py.backup run_server.py

# Start over
```

---

## üìû CONTACT & QUESTIONS

If you encounter issues:

1. **Lead-lag results seem wrong**: Check the `lag` sign interpretation in docstring
2. **Sharpe ratios are different**: Expected! Now using industry-standard formula
3. **Performance is slow**: Ensure FIX #5 applied (should be 10x faster)
4. **JSON parsing fails**: Run `python -m json.tool` on output files to see errors
5. **Tests don't pass**: Check diff against `FIXES_PATCH.md` line by line

---

## üìö ADDITIONAL RESOURCES

- Lead-lag analysis explanation: https://en.wikipedia.org/wiki/Cross-correlation
- Sharpe ratio formula: https://en.wikipedia.org/wiki/Sharpe_ratio
- Sortino ratio formula: https://en.wikipedia.org/wiki/Sortino_ratio
- NumPy select(): https://numpy.org/doc/stable/reference/generated/numpy.select.html

---

**Implementation Status**: Ready  
**Last Updated**: 2026-01-11  
**Estimated Total Time**: 3-4 hours  
**Complexity**: Medium (some logic changes, mostly additions)

